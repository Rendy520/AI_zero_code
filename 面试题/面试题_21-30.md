
# AI 零代码应用生成项目中，如何实现不同应用之间的对话记忆隔离？

为了确保每个应用的对话历史和上下文是完全独立的，我采用了 **基于应用 ID** 的 AI Service 实例隔离策略。

具体实现方式如下：

1）我并没有在 Spring 容器中注册一个单例的 `AiCodeGeneratorService`，而是通过一个 `AiCodeGeneratorServiceFactory` 工厂类来动态创建服务实例。

2）在工厂的 `createAiCodeGeneratorService` 方法中，会根据传入的 `appId` 来创建一个专属的 `MessageWindowChatMemory` 实例。这个记忆实例的 `id` 被设置为 `appId`，并且它会使用配置好的 `RedisChatMemoryStore` 进行持久化。

3）由于每个 `MessageWindowChatMemory` 都有一个唯一的 `id`，LangChain4j 在 Redis 中存储数据时，会生成类似 `langchain4j:chat_memory:{appId}` 这样的 Key，在物理上保证了不同应用对话记忆的隔离。

通过这种方式，每次与特定应用进行对话时，都会获取到一个绑定了该应用专属对话记忆的 AI Service 实例，实现了彻底的对话隔离。


---


# AI 零代码应用生成项目中，为什么要从数据库加载对话历史到记忆中？完整流程是怎样的？

“从数据库加载对话历史到记忆中” 是为了解决 Redis 中对话记忆可能因过期或服务重启而丢失的问题，保证 AI 即使在长时间未交互后，依然能够获取完整的历史上下文。

具体解释一下：Redis 中的数据通常会设置过期时间以控制内存占用。如果一个应用长时间没有交互，其在 Redis 中的对话记忆可能会被自动清除。但我在数据库的 `chat_history` 表中持久化了所有对话。因此，在开始新的对话前，从数据库加载最近的历史记录到 Redis 记忆中，可以实现记忆的恢复，保证对话的连续性。

完整流程如下：

1.  触发时机：在 `AiCodeGeneratorServiceFactory` 中创建新的 AI Service 实例时，会同步触发历史加载逻辑。
2.  查询数据库：`ChatHistoryService` 的 `loadChatHistoryToMemory` 方法会根据 `appId` 查询 `chat_history` 表中最近的 N 条对话记录（比如20条）。查询时会按创建时间降序排列。
3.  排除最新消息：查询时会跳过最新的一条用户消息，因为该消息在调用 AI 服务时会被自动添加到记忆中，排除它可以防止重复。
4.  清空旧记忆：在加载前，会先调用 `chatMemory.clear()` 清空 Redis 中可能存在的旧的、不完整的记忆，防止数据错乱。
5.  顺序加载：将从数据库查出的消息列表进行反转，确保是按时间正序，然后遍历列表，根据消息类型将其逐条添加到 `MessageWindowChatMemory` 实例中，这个过程会将历史对话写入 Redis。

这样，每次对话开始时，AI 的记忆都被预热到了最近的状态，从而能够进行连贯的、有上下文的对话。


---


# AI 零代码应用生成项目中，你如何配置 Caffeine 的缓存策略？

因为在做对话记忆这个模块的时候，我们想隔离会话记忆，就给每个应用分配了专属的AI Service，每个AI Serivce绑定独立的对话记忆。

每次构造完 appId 对应的 AI 服务实例后，利用 Caffeine 缓存来存储，之后相同


---


# AI 零代码应用生成项目中，你在后端如何实现可视化修改功能？

可视化修改功能的核心在于将用户的视觉选择（点击哪个元素）和文本需求（想怎么改）结合起来，然后驱动 AI 对已有的代码文件进行精确的增量修改。

![img](https://pic.code-nav.cn/mianshiya/question_picture/markdown/pdvT18tg_1753196029132-e26788ce-0146-4067-8534-599eeb53bcb2_mianshiya.png)

后端的实现逻辑如下：

1）前端信息收集与传递：用户在前端 `iframe` 中点击一个网页元素后，前端脚本会捕获该元素的信息，并将其与用户的修改指令拼接成一个新的、更丰富的提示词。

2）后端接收增强提示词：后端接收到这个包含了上下文信息的增强提示词。

3）为 AI 提供文件操作工具：为了让 AI 能够进行增量修改，我为 AI Service 注入了一系列文件操作工具，包括：

-   `FileReadTool`：读取指定文件的内容。
-   `FileModifyTool`：用新内容替换文件中的指定旧内容。
-   `FileDeleteTool`：删除文件。
-   `FileDirReadTool`：递归读取目录结构。

4）AI 的自主决策与执行：AI 接收到增强提示词后，会进入一个自主的 **思考-行动** 循环：

-   思考：AI 首先会分析需求，它可能会调用 `readDir` 工具来了解当前的项目结构，然后调用 `readFile` 工具来读取需要修改的文件的原始内容。
-   行动：在读取并理解了文件内容后，AI 会根据用户的修改指令，决定如何修改代码。然后，它会调用 `FileModifyTool`，并提供三个关键参数：要修改的文件路径、需要被替换的旧内容，以及替换后的新内容。

5）后端执行工具并返回结果：后端捕获到 AI 的工具调用请求，实际执行文件修改操作，并将执行结果返回给 AI。AI 再根据这个结果决定是继续修改还是结束任务。


---


# 在为 AI 大模型设计文件操作工具时，如何保证安全性？

分为文件遍历，文件修改，文件删除三部分 1.在进行文件遍历时，首先根据相对路径，拼接出绝对路径，然后还会进行校验，防止ai直接遍历根目录下的所有文件，严格限定只会遍历应用专属目录下的文件。 2.在执行文件删除时，将vue工程项目的核心结构进行比对，如果要删除的文件是这些核心文件，则拒绝操作。 3,在


---


# AI 零代码应用生成项目后期为什么要引入 LangGraph4j 来构建 AI 工作流？和之前的方式相比，解决了什么问题？

项目后期引入 `LangGraph4j` 来构建 AI 工作流，主要是为了解决直接调用 AI Service 模式下存在的流程不可控、任务耦合度高和扩展性差的问题，提升复杂任务的稳定性和可维护性。

![img](https://pic.code-nav.cn/mianshiya/question_picture/markdown/gftXyKhY_1755762605413-33ebd390-5157-450e-bca1-d45bfc970c59_mianshiya.png)

之前直接调用 AI Service 的方式，虽然能完成任务，但存在痛点：

-   流程黑盒与随机性：整个代码生成过程被封装在单一的 AI 调用中，很难干预中间过程。比如，我希望 AI 在生成代码前，先去搜集一些真实的图片素材，但 AI 可能会忘记或选择不执行这个步骤，导致生成结果的随机性很大。
-   任务耦合：如果像搜集图片、增强提示词、生成代码、质量检查这些逻辑上独立的步骤，都被耦合在一个巨大的提示词里，让 AI 一次性完成。这不仅使得提示词变得异常复杂和难以维护，也增加了 AI 理解和执行任务的难度。
-   扩展和优化困难：如果想在流程中增加一个新的步骤，比如 “代码质量检查不通过则返回重试”，在单一 AI Service 模式下几乎无法实现。只能寄希望于优化提示词，但是可能效果不佳且不稳定。

引入 `LangGraph4j` 工作流后，这些问题得到了很好的解决：

-   工作流将一个复杂的任务分解为一系列明确的、可控的节点和边。我可以强制规定任务必须按照图片收集 -> 提示词增强 -> 代码生成 -> 质量检查的顺序执行，将黑盒流程变成了白盒的、标准化的流程，极大地降低了随机性。
-   每个节点只负责一个单一的、具体的任务。比如，图片收集节点只关心如何获取图片，代码生成节点只关心如何生成代码。这样每个节点的逻辑都更简单、更内聚，易于开发、测试和维护。
-   高度的可扩展性与灵活性：`LangGraph4j` 支持条件边和循环。我可以轻松地实现 “如果质量检查失败，就回到代码生成节点重试” 这样的复杂逻辑。未来如果想增加新步骤，只需定义一个新的节点并将其接入到工作流图中即可，对现有流程的侵入性极小。

![](https://pic.code-nav.cn/mianshiya/question_picture/markdown/yAwnyRJ2_202508221400391_mianshiya.png)


---


# 描述一下 AI 代码生成工作流的核心节点、以及它们之间的数据流转？

代码生成工作流是将一个复杂的网站生成任务分解为一系列有序的、自动化的步骤。这些步骤被定义为工作流中的节点，数据则通过一个共享的状态对象 `WorkflowContext` 在节点之间进行传递。

1）图片收集节点 (`image_collector`)

-   输入：从 `WorkflowContext` 中获取 `originalPrompt`。
-   处理：调用 AI 分析提示词，并发地使用图片搜索、插画搜索、Logo生成等工具，收集网站所需的图片素材。
-   输出：将收集到的图片信息列表 `imageList` 更新回 `WorkflowContext`。

2）提示词增强节点 (`prompt_enhancer`)

-   输入：从 `WorkflowContext` 中获取 `originalPrompt` 和 `imageList`。
-   处理：将图片素材的信息（比如描述和URL）整合成一段格式化的文本，并追加到原始提示词的末尾，形成一个信息更丰富的“增强提示词”。
-   输出：将 `enhancedPrompt` 更新回 `WorkflowContext`。

3）智能路由节点 (`router`)

-   输入：从 `WorkflowContext` 中获取 `originalPrompt`。
-   处理：调用 AI 智能路由服务，根据用户需求的复杂度，决策出最合适的代码生成类型（HTML、多文件或Vue工程）。
-   输出：将 `generationType` 更新回 `WorkflowContext`。

4）代码生成节点 (`code_generator`)

-   输入：从 `WorkflowContext` 中获取 `enhancedPrompt` 和 `generationType`。
-   处理：根据指定的生成类型，调用相应的 AI Service，使用增强后的提示词来生成网站代码。如果质检失败，还会接收 `qualityResult` 进行代码修复。
-   输出：将生成代码所在的目录路径 `generatedCodeDir` 更新回 `WorkflowContext`。

5）代码质量检查节点 (`code_quality_check`)

-   输入：从 `WorkflowContext` 中获取 `generatedCodeDir`。
-   处理：读取生成的所有代码文件，拼接后调用一个专门的 AI 服务来检查是否存在语法错误或结构问题。
-   输出：将检查结果 `qualityResult` (包含是否通过、错误列表、改进建议) 更新回 `WorkflowContext`。

6）项目构建节点 (`project_builder`)

-   输入：从 `WorkflowContext` 中获取 `generatedCodeDir` 和 `generationType`。
-   处理：如果生成的是 Vue 工程，则在此节点执行 `npm install` 和 `npm run build` 命令进行打包。
-   输出：将最终可供部署的目录路径 `buildResultDir` 更新回 `WorkflowContext`。

完整流程如图：

![](https://pic.code-nav.cn/mianshiya/question_picture/markdown/yck6fSOR_202508221400439_mianshiya.png)


---


# 在 AI 工作流的图片收集节点中，你是如何实现对多个图片工具的并发调用的？

在图片收集节点中，为了最大化效率，避免串行调用多个耗时的图片 API，我采用了基于 Java `CompletableFuture` 的并发执行方案，内容图片搜索、插画搜索、架构图生成和 Logo 生成这 4 个任务可以同时进行，显著缩短了图片素材的准备时间。

实现流程如下：

1）节点首先会调用一个 **图片收集规划 AI 服务**。这个服务会分析用户的原始提示词，并返回一个结构化的 `ImageCollectionPlan` 对象。这个计划对象中详细列出了需要执行的各类图片任务及其参数，比如需要搜索哪些关键词的内容图片、需要生成什么描述的 Logo 等。

2）拿到这个计划后，程序会遍历计划中的各项任务，并为每个任务创建一个 `CompletableFuture.supplyAsync()` 异步任务。比如，遍历 `contentImageTasks` 列表，为每个任务都提交一个调用 `imageSearchTool.searchContentImages()` 的异步请求到线程池中。所有这些 `CompletableFuture` 对象被收集到一个列表中。

3）使用 `CompletableFuture.allOf(futures.toArray(new CompletableFuture[0])).join()` 来阻塞等待任务列表中的所有异步任务执行完毕。

4）所有任务都完成后，遍历 `CompletableFuture` 列表，通过 `get()` 方法获取每个任务返回的图片资源列表，并将它们全部汇总到一个最终的 `collectedImages` 列表中。

5）最后，将这个包含了所有并发收集到的图片的 `collectedImages` 列表更新到工作流的 `WorkflowContext` 中，供后续节点使用。

通过这种模式，将原本需要依次等待多个网络请求和 AI 计算的串行流程，变成了一个并行的流程，实测这种优化将图片收集的耗时缩短了 70 多秒。

当然，我还实践过利用 LangGraph4j 的并发分支（和子图）能力实现并发。只需要把每个图片收集工具定义成工作节点（或子图），然后配置线程池，就可以并发执行这些工具，最后再统一汇总结果。

![](https://pic.code-nav.cn/mianshiya/question_picture/markdown/83l3TckC_202508221401070_mianshiya.png)


---


# AI 零代码应用生成项目中，如何实现应用封面图自动生成？Selenium 有什么作用？为什么选择它？

封面图自动生成是在应用成功部署后，由后端服务异步触发的一个自动化任务，核心流程如下：

1.  应用部署成功后，会获得一个可公网访问的稳定URL。
2.  使用 Selenium WebDriver 启动一个在后台运行的无头 Chrome 浏览器，访问上述 URL。
3.  程序会等待页面完全加载后，执行屏幕截图操作。
4.  对截图进行压缩以优化体积，然后上传到腾讯云 COS 对象存储，并获取返回的图片链接。
5.  将图片链接更新到数据库中对应应用的 `cover` 字段，并删除服务器上的临时截图文件。

![](https://pic.code-nav.cn/mianshiya/question_picture/markdown/R2aaPsGs_202508221401351_mianshiya.png)

Selenium 的核心作用是驱动一个真实的浏览器环境来完整渲染页面并截图。因为我们平台生成的应用是动态渲染的，仅靠 HTTP 请求无法获取最终呈现给用户的画面。Selenium 能确保所有 JavaScript 都已执行，DOM 完全构建，这样截取到的才是 “所见即所得” 的真实效果。

选择 Selenium 主要是基于稳定性、生态和对现代前端的兼容性考虑。相比 `HtmlUnit` 等工具有限的 JS 支持，Selenium 能完美处理 Vue/React 等复杂前端应用。同时，它在 Java 生态中非常成熟，可以结合 `WebDriverManager` 自动管理浏览器驱动，简化环境配置，是实现这个功能稳定可靠的选择。

![img](https://pic.code-nav.cn/mianshiya/question_picture/markdown/OYFabceK_1755762683751-9fff64db-b204-4dea-9798-0a0eaae51221_mianshiya.png)


---


# AI 零代码应用生成项目中，为什么截图服务要设计为异步执行？如何实现异步？

将截图服务设计为异步执行，主要是为了优化用户体验和提升系统吞吐量。

截图是一个耗时较长的 I/O 密集型操作，需要网络请求、页面渲染、文件上传等步骤。如果同步执行，用户在点击部署后需要等待数秒甚至更久才能得到响应，体验很差。异步化之后，部署请求可以立即返回，封面图生成任务则在后台处理，用户几乎无感知，极大提升操作的流畅度。同时，主业务线程也能被迅速释放，去处理其他用户请求，提高系统的并发处理能力。

在 Java 21 中，我选择使用虚拟线程来实现异步，优势非常明显：

1.  虚拟线程由 JVM 管理，创建和切换的开销极低，可以在单个 JVM 中创建数百万个。而传统线程与操作系统线程 1:1 映射，资源开销大，数量有限。
2.  对于截图之类的 I/O 密集型任务，虚拟线程在等待 I/O 操作时会自动让出底层平台线程，而不是阻塞它。这样少量的平台线程就能支撑海量的并发任务，提高资源利用率和系统吞吐量。
3.  虚拟线程的 API 与传统线程几乎一致，开发者可以用熟悉的代码风格来编写高并发程序，代码更易于维护。
