---
created: 2025-12-29T15:55:20 (UTC +08:00)
tags: [,Java,Python,JavaScript,前端,C语言,C++,Go语言,程序员,编程学习,IT教程,自学编程,软件开发,项目实战,编程导航,开发者交流社区,编程资源,计算机]
source: https://www.codefather.cn/course/1948291549923344386/section/1956193053098504193
author: 
---

# 13 - 可观测性 - 【大厂必备】LangChain4j + 工作流

> ## Excerpt
> 本节重点 本节我们将为 AI 零代码应用生成平台添加全面的可观测性能力，让系统运行状态变得透明可见，为用户提供可靠稳定的服务。可观测性不仅有利于性能优化，也是现代软件架构的必备技能。 本。编程导航教程分享，做您编程学习路上的导航员。

---
## 本节重点

本节我们将为 AI 零代码应用生成平台添加全面的⁠可观测性能力，让系统运行状态变得⁠透明可见，为用户提供可靠稳定的服务。可观测性不仅有利于性能优化，也是现代软件架构的必备技能。

本节主要内容包括：nShO7+0zZStNyiJdnnoFDwT4JyyptzNsRjyXLsolAAU=

-   可观测性介绍
-   ARMS 系统监控
-   Prometheus + Grafana 业务监控

本节可独立于任何项目学习，你将掌握如⁠何为复杂的 AI 应用构⁠建完整的监控体系，实现对系统负载、接口调用情况、业务统计等全方位的监控分析。

## 一、可观测性介绍

### 基本概念

可观测性（Observability）指通过系统的外部输出推断其内部状态的能力。在软件开发中，可观测性是指通过日志、指标和追踪等数据，全面了解系统的运行状况，**以便及时发现和解决问题**。

你可以简单将其理解为 “监控”，但它又比监控的概念更广更深，推荐阅读 [大厂文档](https://www.aliyun.com/getting-started/what-is/what-is-observability) 来进一步了解。qo3wYiJtEuojZDmpW2HRDEwGWUH1DzVFQ47Zs4YmYuk=

### 相关概念

接下来，我们了解一些和可观测性有关的概念。

#### 维度和指标

维度（Dimension）是用⁠来描述和分类数据的标⁠签属性，比如用户 ID、应用 ID、模型名称等，关注 “是什么”。

指标（Metric）是用来量⁠化的数值数据，比如⁠请求次数、响应时间、Token 消耗量等，关注 “有多少”。

简单来说，维度是可以用来筛选的标签，指标是用来计算的数值。nShO7+0zZStNyiJdnnoFDwT4JyyptzNsRjyXLsolAAU=

举个例子：

-   维度：user\_id=12345, app\_id=67890, model\_name=deepseek-chat
-   指标：requests\_total=100, response\_time=1.5s, tokens\_used=2000

#### 监控的数据分类

在实现可观测性时，我们需要关注多种不同类型的数据：

1）系统指标：包括 CPU ⁠使用率、内存占用、⁠磁盘 I/O、网络流量等基础设施层面的监控数据。

2）应用指标：涵盖接口响应时⁠间、QPS（每秒查⁠询率）、错误率、JVM 状态等应用层面的性能数据。WBpr9WI72APgOj+DCCZKObs+ofP0VhBHSvqSELGriv0=

3）业务指标：针对我们平台的⁠特定业务逻辑，比如⁠ AI 模型调用次数、Token 消耗量、用户活跃度等。

4）调用链：在分布式系统中，一个请求可能经过多个服务组件。**Trace** 表示一个完整请求的调用链路，而 **Span** 则代表调用链中的一个操作单元。通过分析 Trace 和 Span，我们可以清晰地看到请求在系统中的流转过程，快速定位性能瓶颈。

![](https://pic.code-nav.cn/course_picture/1608440217629360130/Ff74D8svT0dnLCTI.webp)cZq9/nGwbRXl38gxWuOGAJfnulyo9Sx2vt9GhAJuMwQ=

#### **百分位数**

在性能监控中，我们经常会看到 P50、P75、P90、P99 这些指标，它们被称为 **百分位数**。

-   P50：中位数，表示 50% 的请求响应时间都在这个值以下
-   P75：75% 的请求响应时间都在这个值以下
-   P90：90% 的请求响应时间都在这个值以下
-   P99：99% 的请求响应时间都在这个值以下

举个例子，如果一个接口的 P99 响应时间是 500ms，这意味着⁠ 99% 的请求都能在 500ms 内完成，⁠只有 1% 的请求可能超过这个时间。P99 指标对于发现系统中的异常情况特别有用，因为它能反映出那些偶发的长尾延迟问题。

![](https://pic.code-nav.cn/course_picture/1608440217629360130/V175yWyRWRI20B7K.webp)

💡 注意，别把这玩意跟优先级 P0、P1、P2 搞混了。dWCTYpHEFA/xV8BrvOpKRqkO1d88b9Ip8VkvBeLuZho=

### 怎么实现？

要构建完善的可观测性体系，我们需要解决几个核心问题：

1）统计什么？dWCTYpHEFA/xV8BrvOpKRqkO1d88b9Ip8VkvBeLuZho=

需要根据业务特点确定关键指标，既要覆盖 **系统层面** 的通用指标，也要包含 **业务特有** 的监控维度。

2）如何收集？

数据收集是可观测性的基础，可⁠以通过代码埋点、探⁠针技术、日志分析等多种方式实现。EVevk6+j/BC/ssKO5aUZF8Rusnkp1o/HghJkPkRChGQ=

3）如何存储？

监控数据通常量大且连续，需要⁠选择合适的存储方案⁠，比如时序数据库或专门的监控系统。

4）如何展示？qo3wYiJtEuojZDmpW2HRDEwGWUH1DzVFQ47Zs4YmYuk=

最终需要通过直观的图表和仪表⁠板将数据呈现给用户⁠，一般会实时监控（页面自动刷新）。

![](https://pic.code-nav.cn/course_picture/1608440217629360130/qHPCZbzOMeTg6vTR.webp)

接下来，在本项目中，我会带大⁠家实战下面 2 种⁠主流的可观测性实现方式：p+CfRPZxNEuU7hG8dzfPcN4R10eC9eypGHmTaRf/x7c=

1）利用 ARMS 平台进行系统指标监控⁠：这是一种开箱即用的方案，⁠通过集成阿里云 ARMS 等监控平台，可以快速获得系统层面的全面监控能力。

2）利用 Prometheus + Grafana 自定义业务指标监控：这是目前最主流的开源监控方案，提供了强大的自定义能力和丰富的生态支持。

**💡** 其实大多数非企业级的项目，直接利用数据库和日志进行业务指标统计也足够了。毕竟多接入一个系统，就多一份成本。1vM0bC71h2RCfUkazMGszlP9tIpAZTvdkFrdc8O6/+w=

## 二、ARMS 系统监控

### 什么是 ARMS？

[ARMS](https://armsnext.console.aliyun.com/) 是阿里云提供的应用实时监控服务，采用了探针技术，**能够在不修改应用代码的情况下**，自动收集和分析应用性能数据，快速构建实时的监控能力。F+kzRHG1248BgN91hBPqtNxbML3nLzvb0nw4jU7NTyI=

还记得我们刚刚讲的 “怎么实⁠现可观测性” 的 ⁠4 个核心问题么？ARMS 给出了这样的答案：

1）统计什么？

ARMS 能够监控 Java 应用性能（CPU⁠、内存、线程、GC 等）、应用⁠调用链追踪、异常分析诊断、请求数、错误数、平均耗时、连接池/线程池监控等全方位指标。WBpr9WI72APgOj+DCCZKObs+ofP0VhBHSvqSELGriv0=

2）如何收集？

通过 Java Agent ⁠技术，在 JVM ⁠启动时加载监控代理，实现无侵入式的数据收集。

3）如何存储？dWCTYpHEFA/xV8BrvOpKRqkO1d88b9Ip8VkvBeLuZho=

数据存储在阿里云的分布式存储系统中，用户无需关心存储细节。

4）如何展示？

ARMS 提供了丰富的 We⁠b 控制台，支持多⁠维度的数据分析和可视化展示。1vM0bC71h2RCfUkazMGszlP9tIpAZTvdkFrdc8O6/+w=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/87bpmb4TLSndjlrS.webp)

### 接入 ARMS

在使用任何云产品之前，我们都需要先了解其 [计费规则](https://help.aliyun.com/zh/arms/application-monitoring/product-overview/billing-description)，保护好自己的 money。cZq9/nGwbRXl38gxWuOGAJfnulyo9Sx2vt9GhAJuMwQ=

好在 ARMS 提供的免费资源，一般足够个人测试使用：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/IkWBjGwbr9Wuqtmc.webp "null")

下面我们来接入 ARMS，首先访问 [ARMS 控制台](https://arms.console.aliyun.com/?accounttraceid=f665b274f2dd4a82b30ae1ac90df7514lmmw#/intgr/integrations?menu=server-app)，第一次使用需要开通服务。qo3wYiJtEuojZDmpW2HRDEwGWUH1DzVFQ47Zs4YmYuk=

进入接入中心，选择 Java 应用监控：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/aUb058SfSQxzHXh0.webp)

选择手动安装 Agent：p+CfRPZxNEuU7hG8dzfPcN4R10eC9eypGHmTaRf/x7c=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/VyDg2u0iPFGtZsZn.webp "null")

按照指引下载 Agent 包：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/GJv0OvRW3FdsDL5K.webp)qo3wYiJtEuojZDmpW2HRDEwGWUH1DzVFQ47Zs4YmYuk=

从这里下载：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/Uo6pGZI7mHXs8uCX.webp "null")

下载完成后解压到合适的位置，比如鱼皮这里的解压路径是 `/Users/yupi/Tools/AliyunJavaAgent/aliyun-java-agent.jar`。qo3wYiJtEuojZDmpW2HRDEwGWUH1DzVFQ47Zs4YmYuk=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/o0fyqsyv6AHTMb01.webp)

复制启动命令，注意替换目录路⁠径和应用名称。应用⁠名称可以自定义，建议使用有意义的名称便于后续管理。

你也可以选择开启应用安全功能，它能够提供 [应用层面的安全监控能力](https://help.aliyun.com/zh/arms/application-security/product-overview/what-is-application-security?spm=5176.arms.console-base_help.dexternal.7c48f167HlhHqR)，帮你抵御一些漏洞攻击。WBpr9WI72APgOj+DCCZKObs+ofP0VhBHSvqSELGriv0=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/rSnBKzNrDmijQ9iD.webp)

在 IDE 中编辑项目的启动配置，将复制的命令参数添加到 `VM options` 中：

```bash
-javaagent:/Users/yupi/Tools/AliyunJavaAgent/aliyun-java-agent.jar
-Darms.licenseKey=xxx
-Darms.appName=yu-ai-code-mother
```

⚠️ 注意，需要将参数间的换行替换为空格！

![](https://pic.code-nav.cn/course_picture/1608440217629360130/Ixw0r2pKZEkQURCy.webp)

接下来启动项目。启动会比平时⁠慢一些，这是正常的⁠，因为引入 Agent 会拖慢启动速度。qo3wYiJtEuojZDmpW2HRDEwGWUH1DzVFQ47Zs4YmYuk=

看到下图信息就表示启动成功了，默认数据会上报到杭州区域：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/D0SjGIvlBsgDf0fF.webp)

最后，回到 ARMS 控制台⁠的应用列表页面，就⁠能看到刚刚接入的应用了：dWCTYpHEFA/xV8BrvOpKRqkO1d88b9Ip8VkvBeLuZho=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/FqA2FqXzpO5PBIPR.webp)

### 指标监控

下面我们来看看 ARMS 都⁠提供了哪些指标的监⁠控，有个印象就好。F+kzRHG1248BgN91hBPqtNxbML3nLzvb0nw4jU7NTyI=

#### 应用概览

点击进入应用详情页，首先看到⁠的是应用概览 T⁠ab。建议切换到新版视图，豁然开朗。

![](https://pic.code-nav.cn/course_picture/1608440217629360130/RloAFfXICcDzWVoQ.webp)F+kzRHG1248BgN91hBPqtNxbML3nLzvb0nw4jU7NTyI=

在这个页面可以看到应用的核心⁠性能指标，包括请求⁠数、响应时间、错误数等关键数据。

#### 应用拓扑

应用拓扑页面展示了项目的依赖⁠关系图，可以清晰地⁠看到应用和各种中间件的连接情况：WBpr9WI72APgOj+DCCZKObs+ofP0VhBHSvqSELGriv0=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/SZqDw7uPlzUbMeW7.webp "null")

这个视图对于理解系统架构和排查依赖问题有用。

#### 提供服务

提供服务页面能够统一展示所有⁠接口的调用情况，包⁠括请求量、错误数、平均耗时等核心指标：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/AYlGMIecYfR8qqvi.webp)

点击具体接口还可以深入分析该⁠接口的详细数据（这⁠就是所谓的 “下钻分析”）：1vM0bC71h2RCfUkazMGszlP9tIpAZTvdkFrdc8O6/+w=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/PsHGLgCTkTpwQDlD.webp)

ARMS 还提供了 SQL ⁠调用分析功能，能够⁠监控数据库操作的性能：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/hUG66MiCq3sKXfWF.webp "null")qo3wYiJtEuojZDmpW2HRDEwGWUH1DzVFQ47Zs4YmYuk=

以及 NoSQL（如 Redis）的调用分析：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/aZiPoqkk8ilOmPTd.webp "null")

还提供了异常分析功能，可以帮⁠助快速定位和解决应⁠用中的异常问题：qo3wYiJtEuojZDmpW2HRDEwGWUH1DzVFQ47Zs4YmYuk=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/Id5c5mZOt8WbMpLC.webp)

#### 调用链分析

调用链分析是 ARMS 的核⁠心功能之一，可以深⁠度分析单次请求的完整调用路径，快速定位瓶颈点：WBpr9WI72APgOj+DCCZKObs+ofP0VhBHSvqSELGriv0=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/ZAqZMvTFwxnnY00S.webp)

点击具体的调用记录，在 Tra⁠ce 详情页面可以看⁠到请求经过的每个环节和对应的耗时，右侧还能显示当时的 JVM 状态：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/gPSdgQAndcMETFpA.webp)dWCTYpHEFA/xV8BrvOpKRqkO1d88b9Ip8VkvBeLuZho=

在全链路聚合页面可以清晰地看到树形的调用结构：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/kFAqeyMXYzQ35yyj.webp)

点击分析后，会根据特定的 s⁠erviceNam⁠e 和 span 进行过滤分析：dWCTYpHEFA/xV8BrvOpKRqkO1d88b9Ip8VkvBeLuZho=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/IkJAaZk919etym0I.webp)

其中，错误 / 慢 Trac⁠e 分析功能特别实⁠用，能够一秒定位到性能瓶颈：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/AFT7QTtFEWIfia7j.webp)qo3wYiJtEuojZDmpW2HRDEwGWUH1DzVFQ47Zs4YmYuk=

#### 依赖服务

依赖服务页面专门监控应用对外⁠部服务的调用情况，⁠比如数据库、缓存等：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/kmIJTI2GeXQgrCD8.webp)EVevk6+j/BC/ssKO5aUZF8Rusnkp1o/HghJkPkRChGQ=

可以深入到具体依赖的详情页面，比如数据库详情：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/bUtHfhG7OlqS7Bgg.webp)

这里能够看到执行的具体 SQ⁠L 语句和慢 SQ⁠L，一目了然！qo3wYiJtEuojZDmpW2HRDEwGWUH1DzVFQ47Zs4YmYuk=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/jCCnsqWbpYQgZWs4.webp)

还能分析哪些请求对数据库的消耗最大：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/17eOatnDInCCVetZ.webp)nShO7+0zZStNyiJdnnoFDwT4JyyptzNsRjyXLsolAAU=

#### 实例监控

实例监控页面展示服务器本身的运行状态：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/o89Tj7Ol4w0v9SJB.webp)WBpr9WI72APgOj+DCCZKObs+ofP0VhBHSvqSELGriv0=

可以深入查看某个实例的详细信息：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/RTuMf98t2QmQzmSP.webp)

JVM 监控提供了堆内存、垃圾回收等关键指标：p+CfRPZxNEuU7hG8dzfPcN4R10eC9eypGHmTaRf/x7c=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/Bu14IjA1nD7kh1Fa.webp)

线程池监控帮助了解线程的使用情况：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/9BCVu34lwBv7txeN.webp)EVevk6+j/BC/ssKO5aUZF8Rusnkp1o/HghJkPkRChGQ=

甚至还有连接池监控，比如数据库连接池：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/gM02eOGZfPiBA2WV.webp)

以及 Redis 连接池：dWCTYpHEFA/xV8BrvOpKRqkO1d88b9Ip8VkvBeLuZho=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/oUSNYHq6XpXgnTvk.webp)

机器负载监控显示了系统层面的资源使⁠用情况，比如 CPU、⁠内存利用率，如果发现利用率较高，可能要考虑升配；较低则表示可能存在浪费。

![](https://pic.code-nav.cn/course_picture/1608440217629360130/2XoyeZVRrsKYDbOT.webp)cZq9/nGwbRXl38gxWuOGAJfnulyo9Sx2vt9GhAJuMwQ=

#### 场景化分析

ARMS 还提供了 5 大场景化分析功能：

-   异常分析
-   日志分析
-   数据库分析
-   调用链分布
-   上下游分析

我感觉异常分析比较实用，能够按照异⁠常名称进行分类展示，可⁠以快速查看某类异常的出现情况，以及查看异常堆栈信息，从而快速定位错误：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/N8M0Zvwpa43EoABZ.webp)

#### 事件分析

事件分析页面用于管理各种告警事件：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/H6u2xHcTc9a9EHzR.webp)

#### 应用配置

在应用配置页面可以设置数据采样率、自定义探针收集的指标：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/Eaq7EPuuX9rK74vf.webp)

还可以开启一些高级功能，比如⁠ Arthas 监⁠控、持续性能剖析等：UzapLzatIvJJsWWs1pRz7879eXluI/+jA6d4qBCHuKE=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/L3nvLLnOMHH8qiRv.webp "null")

不过需要注意的是，收集的数据⁠越多，费用也会相应⁠增加，请按需开启。

#### 应用诊断

开启相关配置后，可以使用应用诊断功能。

持续性能分析能够深入分析应用⁠的性能瓶颈：   ⁠                             

![](https://pic.code-nav.cn/course_picture/1608440217629360130/QeNyCnV6gI2sqhNX.webp)dWCTYpHEFA/xV8BrvOpKRqkO1d88b9Ip8VkvBeLuZho=

智能洞察功能提供自动化的问题发现能力：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/yOiWhbBHsenTa5t4.webp)

线程分析帮助了解线程的执行状态：F+kzRHG1248BgN91hBPqtNxbML3nLzvb0nw4jU7NTyI=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/1fBdBBMDAtiPdmQU.webp)

Arthas 诊断功能集成了阿里巴巴开源的 Java 应用诊断工具 [Arthas](https://arthas.aliyun.com/)，能够在不修改代码、不重启应用的情况下，对运行中的 Java 应用进行实时诊断，包括查看类加载信息、方法执行情况、线程状态等。

![](https://pic.code-nav.cn/course_picture/1608440217629360130/iJ1WyVtYhO5O5AJT.webp)1vM0bC71h2RCfUkazMGszlP9tIpAZTvdkFrdc8O6/+w=

可以分析线程耗时和查看实时堆栈：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/Hllp2lq22uvF9UWY.webp)

通过查看实时堆栈，可以精确定位线程⁠正在执行的任务。如果某⁠个线程出现阻塞，也能清楚地看到阻塞发生的位置，在排查死锁时特别有用。dWCTYpHEFA/xV8BrvOpKRqkO1d88b9Ip8VkvBeLuZho=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/uNfCEk7kEUL6SmbY.webp)

还可以直接连接到应用进行在线诊断：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/Hfp6XZBYhAtkg9GF.webp)qo3wYiJtEuojZDmpW2HRDEwGWUH1DzVFQ47Zs4YmYuk=

💡 友情提示：测试完成后记⁠得关闭不必要的监控⁠功能，避免产生不必要的费用。

### 告警能力

监控和告警天生一对，通常是配⁠套使用的，告警机制⁠能够在问题发生时及时通知相关人员。p+CfRPZxNEuU7hG8dzfPcN4R10eC9eypGHmTaRf/x7c=

创建告警规则的流程很简单：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/lLYdyy9cGk6vHM8O.webp)

ARMS 支持阈值检测和区间⁠检测两种模式。以监⁠控慢 SQL 次数为例：1vM0bC71h2RCfUkazMGszlP9tIpAZTvdkFrdc8O6/+w=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/fBoM4SukngsXfzhP.webp)

可以配置告警通知方式、时间段、重复策略等：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/cRoOt6TXSXStS5mH.webp)WBpr9WI72APgOj+DCCZKObs+ofP0VhBHSvqSELGriv0=

创建完成后，可以在告警规则列表中看到，并且支持测试功能：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/PZeb3hZjLAri0Vfw.webp)

还有一些常见的告警配置，比如应⁠用响应时间超过阈值、⁠错误率超过阈值、数据库连接数过高、JVM 内存使用率过高等。nShO7+0zZStNyiJdnnoFDwT4JyyptzNsRjyXLsolAAU=

💡 不过要注意合理配置告警⁠，而且要配置分级告⁠警，否则可能就会出现大家对告警已经麻了，有告警也不处理的情况。

### 扩展知识 - 怎么自己实现监控平台？

可能有同学好奇，为什么 ARMS 只是在⁠启动命令中加了几个参数，就⁠能实现这么全面的监控功能？而且能够支持那么灵活的筛选？这背后的技术原理是什么？cZq9/nGwbRXl38gxWuOGAJfnulyo9Sx2vt9GhAJuMwQ=

#### 探针技术

首先，数据是通过探针技术 `Java Agent` 收集的。Java Agent 是 JVM 提供的机制，允许在 Java 应用启动时或运行时动态修改字节码，从而实现无侵入式的监控。

利用探针进行监控的原理如下：UzapLzatIvJJsWWs1pRz7879eXluI/+jA6d4qBCHuKE=

1.  字节码增强：Java Agent 通过 Java Instrumentation API 在类加载时拦截字节码，动态插入监控代码。
2.  方法织入：在关键方法（如 HTTP 请求处理、数据库调用等）的入口和出口处织入监控逻辑，记录执行时间、参数、返回值等信息。
3.  数据收集：织入的监控代码会收集各种性能数据，并通过网络传输到监控平台。
4.  链路追踪：通过在请求上下文中传递唯一标识，将分布式调用链串联起来，形成完整的 Trace。

这种方式的优势在于完全不需要⁠修改业务代码，只需⁠要在 JVM 启动时指定 Agent，就能获得全面的监控能力。

![](https://pic.code-nav.cn/course_picture/1608440217629360130/ay43Jm8FeJ47J4Hw.webp)p+CfRPZxNEuU7hG8dzfPcN4R10eC9eypGHmTaRf/x7c=

💡 学过后端架构的朋友应该会发现，探针技术和服务网格的 Sidecar 模式在核心理念上非常相似，都体现了 **无侵入式增强** 的设计思想。能够在不修改原有业务代码（或服务）的前提下，为应用添加监控、治理等横切关注点功能。

![](https://pic.code-nav.cn/course_picture/1608440217629360130/Dc3bZSbkktRcoqok.webp)

它们都采用了代理拦截的工作模式，探针通过字节码增强拦截方法⁠调用、Sidecar 通过网络代理拦截⁠服务通信，本质上都是在应用的执行路径上插入额外的处理逻辑。将业务逻辑和运维监控解耦，让开发者专注于业务开发。F+kzRHG1248BgN91hBPqtNxbML3nLzvb0nw4jU7NTyI=

#### 数据的维度划分

监控平台之所以能提供如此灵活⁠的筛选和分析能力，⁠关键在于合理的数据维度设计。

以一个 HTTP 请求为例，监控系统会记录 **最细粒度** 的维度信息：cZq9/nGwbRXl38gxWuOGAJfnulyo9Sx2vt9GhAJuMwQ=

WBpr9WI72APgOj+DCCZKObs+ofP0VhBHSvqSELGriv0=qo3wYiJtEuojZDmpW2HRDEwGWUH1DzVFQ47Zs4YmYuk=EVevk6+j/BC/ssKO5aUZF8Rusnkp1o/HghJkPkRChGQ=cZq9/nGwbRXl38gxWuOGAJfnulyo9Sx2vt9GhAJuMwQ=p+CfRPZxNEuU7hG8dzfPcN4R10eC9eypGHmTaRf/x7c=cZq9/nGwbRXl38gxWuOGAJfnulyo9Sx2vt9GhAJuMwQ=cZq9/nGwbRXl38gxWuOGAJfnulyo9Sx2vt9GhAJuMwQ=1vM0bC71h2RCfUkazMGszlP9tIpAZTvdkFrdc8O6/+w=dWCTYpHEFA/xV8BrvOpKRqkO1d88b9Ip8VkvBeLuZho=UzapLzatIvJJsWWs1pRz7879eXluI/+jA6d4qBCHuKE=dWCTYpHEFA/xV8BrvOpKRqkO1d88b9Ip8VkvBeLuZho=cZq9/nGwbRXl38gxWuOGAJfnulyo9Sx2vt9GhAJuMwQ=nShO7+0zZStNyiJdnnoFDwT4JyyptzNsRjyXLsolAAU=p+CfRPZxNEuU7hG8dzfPcN4R10eC9eypGHmTaRf/x7c=

|维度|示例值|说明nShO7+0zZStNyiJdnnoFDwT4JyyptzNsRjyXLsolAAU=|
|---|---|---|
|时间戳|2025-08-14 19:30:10|请求发生的精确时间WBpr9WI72APgOj+DCCZKObs+ofP0VhBHSvqSELGriv0=|
|应用名|yu-ai-code-mother|应用标识F+kzRHG1248BgN91hBPqtNxbML3nLzvb0nw4jU7NTyI=|
|接口路径|/api/app/gen⁠erate|具体的接口cZq9/nGwbRXl38gxWuOGAJfnulyo9Sx2vt9GhAJuMwQ=|
|HTTP 方法|POST|请求⁠方法1vM0bC71h2RCfUkazMGszlP9tIpAZTvdkFrdc8O6/+w=|
|响应状态码|200|请求结果dWCTYpHEFA/xV8BrvOpKRqkO1d88b9Ip8VkvBeLuZho=|
|响应时间|150ms|接口耗时cZq9/nGwbRXl38gxWuOGAJfnulyo9Sx2vt9GhAJuMwQ=|
|客户端 IP|127.0.0.1|请求来源UzapLzatIvJJsWWs1pRz7879eXluI/+jA6d4qBCHuKE=|
|用户 ID|12345|业务维度dWCTYpHEFA/xV8BrvOpKRqkO1d88b9Ip8VkvBeLuZho=|

基于这些最细粒度的数据，监控⁠平台就可以进行各种⁠维度的聚合分析，比如：

-   按时间聚合：统计每分钟/小时/天的请求量
-   按接口聚合：分析各接口的性能表现
-   按状态码聚合：计算成功率和错误率
-   按用户聚合：分析用户行为模式

## 三、Prometheus + Grafana 业务监控

前面我们通过 ARMS 实现了系统级的监控，这种方式简单高效，适合⁠快速获得全面的监控能力。但 ARMS 主要关⁠注通用的系统指标，如果我们想监控业务特有的指标，比如大模型的 Token 使用量、用户的活跃度等，就需要自定义的监控方案。

回到最初的几个核心问题，都需要⁠我们自己来考虑了： ⁠                               dWCTYpHEFA/xV8BrvOpKRqkO1d88b9Ip8VkvBeLuZho=

1.  统计什么？监控 AI 模型调用相关的业务指标
2.  如何收集？通过在代码中埋点的方式主动收集数据。
3.  如何存储？使用 Prometheus 时序数据库存储指标数据。
4.  如何展示？通过 Grafana 构建可视化监控仪表板。

下面我们进入方案设计阶段，依次对这几个问题进行展开。

### 监控指标设计

首先我们需要明确要监控哪些维度和业务指标。根据 [LangChain4j 可观测性文档](https://docs.langchain4j.dev/tutorials/observability)，我们可以获取到以下数据：

#### 维度

-   用户 ID
-   应用 ID
-   模型名称
-   最大输出 Token 数（maxOutputTokens）
-   AI 回复消息内容
-   模型生成停止的原因（Finish Reason）
-   调用状态（成功或失败）
-   请求时间
-   调用失败时的错误信息

#### 指标

-   输入 Token 数量
-   输出 Token 数量
-   总消耗 Token 数量
-   响应时长

#### 分析能力

有了上面这些数据，我们能够进行很多分析：

-   模型调用分析：统计不同时间窗口（分钟/小时/天）内各模型、用户、应用的调用次数趋势
-   模型性能分析：分析各模型的平均响应时间，以及响应时间分布的 P50/P90/P95/P99 百分位数
-   Token 消耗分析：监控不同时间窗口（分钟/小时/天）内输入 Token、输出 Token、总 Token 的消耗
-   热门应用排行：按调用次数对应用进行排序，识别调用 AI 最频繁的应用
-   用户活跃排行：按调用次数对用户进行排序，识别调用 AI 最频繁的用户
-   应用 Token 消耗排行：按 Token 消耗量对应用进行排序，识别消耗最高的应用
-   用户 Token 消耗排行：按 Token 消耗量用户进行排序，识别消耗最高的用户
-   错误分析：统计各模型的失败次数，以及不同错误类型的分布占比

### 数据收集方式

在业务监控中，数据收集需要开⁠发者手动埋点，因为⁠只有业务开发者才知道要收集什么信息、从哪里收集、什么时候收集。

跟业界主流的可观测性实现方案一样，我们的策略是在业务层收集 **最原始、最细粒度** 的数据，这样在查询层就能进行灵活的聚合分析。

怎么获取原始数据呢？cZq9/nGwbRXl38gxWuOGAJfnulyo9Sx2vt9GhAJuMwQ=

LangChain4j 提供了 [可观测性支持](https://docs.langchain4j.dev/tutorials/observability/)，通过定义 Listener 来获取大模型的调用信息。

![](https://pic.code-nav.cn/course_picture/1608440217629360130/0vslhlmgW1oL3Dxn.webp)

### 数据存储方案 - Prometheus

即使没有学过 Prometh⁠eus，也应该知道⁠可以通过数据库存储的方式实现监控统计。

比如将监控数据存储到 MySQL 等关系型数据库中（或者 ⁠Elasticsearch），之后从数⁠据库中读取。适合需要持久化保存详细数据的场景，而且比较灵活，可以自己写 SQL 实现复杂的查询和关联分析。

但缺点是收集监控数据可能会比⁠较频繁，需要频繁写⁠入数据库，容易对应用性能产生影响。p+CfRPZxNEuU7hG8dzfPcN4R10eC9eypGHmTaRf/x7c=

因此，专业的事情交给专业的中间件来做吧！

#### 什么是 Prometheus？

[Prometheus](https://prometheus.io/docs/introduction/overview/) 是一个开源的监控系统，专门为时序数据的收集、存储和查询而设计。WBpr9WI72APgOj+DCCZKObs+ofP0VhBHSvqSELGriv0=

Prometheus 的核心理念是将所有监控数据以 **时间序列** 的形式存储。根据它的 [数据模型](https://prometheus.io/docs/concepts/data_model/)，每个时间序列都由指标名称和一组标签唯一标识。比如 `http_requests_total{method="POST", handler="/api/yupi"}` 就表示一个记录 POST 请求接口总数的时间序列。

这样一来，Prometheus 能够高效地⁠处理监控场景中的时间范围查询⁠，比如过去一小时内各个接口的平均响应时间、CPU 使用率超过 80% 的服务器列表等。

#### 核心组件架构

Prometheus 包含几个关键组件，职责明确：

1）Prometheus Server：整个系统的核心，负责数据收集、存储和查询。它定期从配置的目标 **拉取** 指标数据，将数据存储在本地的时序数据库中，并提供 PromQL 查询语言来支持复杂的数据分析。

2）Exporter：翻译器，将第三方系统（如数据库、操作系统、消息队列等）⁠的指标转换为 Prometheus 格式。比如 N⁠ode Exporter 可以收集 Linux 系统的 CPU、内存、磁盘等指标，MySQL Exporter 可以收集数据库的性能指标。WBpr9WI72APgOj+DCCZKObs+ofP0VhBHSvqSELGriv0=

3）Alertmanager：处理告警规⁠则和通知分发。当指标触发预⁠设的告警条件时，它负责将告警信息发送给相应的人员或系统，支持邮件等多种通知方式。

4）客户端库：提供各种编程语言的 SDK⁠，方便开发者在应用代码中埋⁠点收集自定义指标。这些库封装了指标类型的创建和管理，让开发者能够专注于业务逻辑。

![](https://pic.code-nav.cn/course_picture/1608440217629360130/XFPPJPIkLy1G9K9h.webp)cZq9/nGwbRXl38gxWuOGAJfnulyo9Sx2vt9GhAJuMwQ=

#### 数据收集原理

Prometheus 采用 **拉取模式** 来收集指标数据，而不是由项目主动推送数据，这是它的核心特征。

它会定期向配置的目标发起 HTTP 请求，从 `/metrics` 端点获取指标数据。1vM0bC71h2RCfUkazMGszlP9tIpAZTvdkFrdc8O6/+w=

拉模式的好处是：

-   简单可靠：基于标准 HTTP 协议，无需复杂的消息队列或特殊的网络配置
-   监控目标的发现和管理更加灵活：Prometheus 可以通过服务发现机制自动发现新的监控目标。而且将监控的控制权交给 Prometheus，可以避免目标服务的监控数据推送失败影响业务逻辑。

我们可以通过 [Jobs 和 Instances](https://prometheus.io/docs/concepts/jobs_instances/) 配置需要拉取的数据任务和服务实例，当 Prometheus 抓取目标时，会自动为每个时间序列添加 `job` 和 `instance` 标签来标识数据来源。同时还会生成一些元指标，比如 `up` 指标表示目标是否可达，`scrape_duration_seconds` 记录抓取耗时，这些信息对于监控系统自身的健康检查非常有用。p+CfRPZxNEuU7hG8dzfPcN4R10eC9eypGHmTaRf/x7c=

#### 指标类型

如果想在项目中自定义指标收集，需要先了解 Prometheus 的 4 种核心 [指标类型](https://prometheus.io/docs/concepts/metric_types/)，每种类型都针对不同的监控场景进行了优化。

1）Counter：累积计数器，只能增加或重置为零，适合统计请求总数、错误次数等单调递增的指标。在我们的 AI 监控场景中，`ai_model_requests_total` 大模型请求总数就是一个典型的 Counter 指标。EVevk6+j/BC/ssKO5aUZF8Rusnkp1o/HghJkPkRChGQ=

2）Gauge：仪表盘类型，数⁠值可以任意上下波动，⁠适合记录当前状态值，比如内存使用量、当前在线用户数、队列长度等。

3）Histogram：直方图类型，用于观察数据⁠分布情况，比如请求响应时间的⁠分布。它会自动生成多个时间序列，包括各个桶的计数、总和以及总数，可以用来计算百分位数等统计指标。

4）Summary：和 Histog⁠ram 类似，但它在客户⁠端预先计算百分位数，适合需要精确百分位数计算但对网络传输有要求的场景。1vM0bC71h2RCfUkazMGszlP9tIpAZTvdkFrdc8O6/+w=

通过合理选择指标类型，我们可⁠以用最小的存储开销⁠获得最大的监控价值。

#### 存储机制

提到拉模式，可能会有朋友误以为 Prometheus 不存储数据，实际上它拥有自己的高性能时间序列数据库 [TSDB](https://prometheus.io/docs/prometheus/latest/storage/)，单节点就能处理数百万个时间序列，满足大部分企业的监控需求。p+CfRPZxNEuU7hG8dzfPcN4R10eC9eypGHmTaRf/x7c=

新写入的数据首先存储在内存中，达到时间阈值（每 2 小时一个数据块）后批量写入⁠磁盘，这种设计在保证查询性能的同时也提供了良好的写入吞⁠吐量。预写日志 WAL 机制确保了数据的可靠性，即使系统崩溃也不会丢失数据                                

![](https://pic.code-nav.cn/course_picture/1608440217629360130/NuWNujC70caqIZJ3.webp)

#### 和传统方案的对比

回到我们的业务监控需求，可以利用 Prometheus 提供的 ⁠Counter 等指标类型，轻松统计 AI⁠ 模型的调用次数、响应时间、Token 消耗等关键指标。因为只是在内存中进行简单的数字递增统计，所以性能比数据库高很多。

具体的对比表格：

UzapLzatIvJJsWWs1pRz7879eXluI/+jA6d4qBCHuKE=EVevk6+j/BC/ssKO5aUZF8Rusnkp1o/HghJkPkRChGQ=nShO7+0zZStNyiJdnnoFDwT4JyyptzNsRjyXLsolAAU=qo3wYiJtEuojZDmpW2HRDEwGWUH1DzVFQ47Zs4YmYuk=qo3wYiJtEuojZDmpW2HRDEwGWUH1DzVFQ47Zs4YmYuk=EVevk6+j/BC/ssKO5aUZF8Rusnkp1o/HghJkPkRChGQ=1vM0bC71h2RCfUkazMGszlP9tIpAZTvdkFrdc8O6/+w=F+kzRHG1248BgN91hBPqtNxbML3nLzvb0nw4jU7NTyI=qo3wYiJtEuojZDmpW2HRDEwGWUH1DzVFQ47Zs4YmYuk=nShO7+0zZStNyiJdnnoFDwT4JyyptzNsRjyXLsolAAU=dWCTYpHEFA/xV8BrvOpKRqkO1d88b9Ip8VkvBeLuZho=

|对比维度|数据库方案|Prometheus 方案dWCTYpHEFA/xV8BrvOpKRqkO1d88b9Ip8VkvBeLuZho=|
|---|---|---|
|核心用途|审计、深度分析、事后追溯|实时监控、性能分析、告警nShO7+0zZStNyiJdnnoFDwT4JyyptzNsRjyXLsolAAU=|
|数据粒度|极高：记录每个请求的全部细节|聚合：只记录统计值，丢失个体请求细节UzapLzatIvJJsWWs1pRz7879eXluI/+jA6d4qBCHuKE=|
|性能⁠影响|较高：每次请求都需要数据库写入|极低：只是内存⁠中的原子操作UzapLzatIvJJsWWs1pRz7879eXluI/+jA6d4qBCHuKE=|
|实时性|差：从海量数据中实时聚合计算很慢 |极好：预聚合数据，查询极快UzapLzatIvJJsWWs1pRz7879eXluI/+jA6d4qBCHuKE=|
|存储成本|非常高：与请求量成正比|非常低：与指标基数成正比cZq9/nGwbRXl38gxWuOGAJfnulyo9Sx2vt9GhAJuMwQ=|

因此，我们肯定是选择 Prometheu⁠s 方案，不仅是因为它更适⁠合实时监控分析的需求，而且它和 Grafana 也能轻松整合，开发成本也很低。

### 什么是 Grafana？

[Grafana](https://grafana.com/) 是一个开源的数据可视化平台，专门用于创建监控看板。它可以连接多种数据源（包括 Prometheus、MySQL、PostgreSQL、Elasticsearch 等），并提供丰富的图表类型和可视化选项。p+CfRPZxNEuU7hG8dzfPcN4R10eC9eypGHmTaRf/x7c=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/nk2O7G5TtyaGL8tj.webp)

虽然 Grafana 是一个功能非常丰富的企业级产品，拥有告⁠警管理、用户权限控制、插件生态、云服务集⁠成等高级特性，但对于我们目前的需求来说，将它当作一个看板工具来使用，知道怎么创建看板和接入数据进行展示就足够了。

### 环境准备

接下来我们先开始搭建 Prometheus + Grafana 监控环境。

为了照顾不便安装 Docker 或不熟悉⁠ Docker 的同学，我⁠这里使用普通的安装方式，会 Docker 的同学用 Docker 启动更方便。

#### Prometheus 安装

1）访问 [Prometheus 下载页面](https://prometheus.io/download/)，选择对应的操作系统和架构：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/crnSw2TvkeXqWKdN.webp)

2）下载并解压到不包含中文路径的目录：WBpr9WI72APgOj+DCCZKObs+ofP0VhBHSvqSELGriv0=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/QpRnPMiZXDik9qsa.webp)

3）查看默认配置文件 `prometheus.yml`：

```yaml
# 全局配置
global:
  scrape_interval: 15s # 全局抓取间隔，默认每15秒抓取一次
  evaluation_interval: 15s # 规则评估间隔

# 告警管理器配置（可选）
alerting:
  alertmanagers:
    - static_configs:
        - targets:
          # - alertmanager:9093

# 规则文件配置
rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

# 抓取配置
scrape_configs:
  # Prometheus 自身监控
  - job_name: "prometheus"
    static_configs:
      - targets: ["localhost:9090"]
        labels:
          app: "prometheus"
```

默认配置会监控 Promet⁠heus 自己，这⁠样我们可以先测试环境是否正常。

💡 [Prometheus Rules](https://prometheus.io/docs/prometheus/latest/getting_started/#configure-rules-for-aggregating-scraped-data-into-new-time-series) 是用于定义监控指标的逻辑规则，包括：

-   记录规则：预计算复杂查询并存储为新时间序列以提升性能，而不需要每次都实时计算复杂的查询表达式。
-   告警规则：定义告警条件并触发通知

4）启动 Prometheus：

```bash
./prometheus --config.file=prometheus.yml
```

启动成功后会在 9090 端口提供服务：EVevk6+j/BC/ssKO5aUZF8Rusnkp1o/HghJkPkRChGQ=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/d17A2YaudvZTQ2XN.webp)

5）访问 [http://localhost:9090](http://localhost:9090/) 进入管理界面，建议开启本地时间（不然时间可能少 8 个小时）：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/5eEKvykqyE3xgYIf.webp "null")nShO7+0zZStNyiJdnnoFDwT4JyyptzNsRjyXLsolAAU=

访问 [http://localhost:9090/metrics](http://localhost:9090/metrics) 可以看到 Prometheus 自身暴露的指标数据：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/0zPxGctwUDWS9dfZ.webp "null")

这就是 Prometheus 期望的指标数据格式，每个应用都需要在 `/metrics` 端点暴露类似的数据。UzapLzatIvJJsWWs1pRz7879eXluI/+jA6d4qBCHuKE=

6）在 Prometheus 查询界面可以输入 [PromQL 表达式](https://prometheus.io/docs/prometheus/latest/querying/basics/) 查看指标：

```plain
prometheus_target_interval_length_seconds
```

这个指标记录了 Prometheus 抓取目标⁠之间的实际时间间隔，比如你配置⁠每 15 秒抓取一次，但实际可能是 14.8 秒或 15.2 秒，这个指标就记录这些实际值。WBpr9WI72APgOj+DCCZKObs+ofP0VhBHSvqSELGriv0=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/j8uhh1E1QxHUmcGp.webp)

结果中的每一行都是一个时间序⁠列，大括号内的是标⁠签（维度）。其中：

-   `quantile="0.01"` 表示第 1 百分位数（最快的 1%）
-   `quantile="0.5"` 表示第 50 百分位数（中位数）
-   `quantile="0.99"` 表示第 99 百分位数（最慢的 1%）

这表示 99% 的抓取都在 15.0012 秒以内完成。

还可以更精确地查询特定百分位数：

```plain
prometheus_target_interval_length_seconds{quantile="0.99"}
```

7）在 Graph 页签可以查看可⁠视化图表，比如计算过去⁠ 1 分钟内 Prometheus 每秒平均创建的内存数据块数：

```plain
rate(prometheus_tsdb_head_chunks_created_total[1m])
```

如图：1vM0bC71h2RCfUkazMGszlP9tIpAZTvdkFrdc8O6/+w=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/SdIqvYk3d221mbHL.webp)

#### Grafana 安装

1）访问 [Grafana 下载页面](https://grafana.com/grafana/download)，根据操作系统选择对应的安装包：dWCTYpHEFA/xV8BrvOpKRqkO1d88b9Ip8VkvBeLuZho=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/WqnXRb21wmEQQ6BN.webp)

2）按照对应系统的 [安装文档](https://grafana.com/docs/grafana/latest/setup-grafana/installation/) 进行安装。比如 Windows 系统直接执行 `grafana-server.exe`，Mac 系统执行下列命令：

```bash
./bin/grafana server
```

启动成功的日志信息：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/olcUvqtJbsctbbCb.webp)

3）访问 [http://localhost:3000](http://localhost:3000/) 查看看板，默认登录账号密码都是 `admin`：WBpr9WI72APgOj+DCCZKObs+ofP0VhBHSvqSELGriv0=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/I45R1VrTVizfdSCF.webp "null")

💡 可以参考 [起始文档](https://grafana.com/docs/grafana/latest/getting-started/build-first-dashboard/) 来学习如何使用 Grafana 构造看板。

#### Grafana 整合 Prometheus

Grafana 与 Prometheus 打配合的 [工作原理](https://grafana.com/docs/grafana/latest/datasources/prometheus/) 很简单：Grafana 通过 HTTP API 从 Prometheus 查询数据，然后以图表形式展示。用户可以编写 PromQL 表达式来实现灵活的数据分析。

下面我们先来跑通一下整合流程。

1）参考 [官方文档](https://grafana.com/docs/grafana/latest/getting-started/get-started-grafana-prometheus/)，登录 Grafana 后，需要先添加 Prometheus 作为数据源：nShO7+0zZStNyiJdnnoFDwT4JyyptzNsRjyXLsolAAU=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/BiYY7edVGKYYrFJz.webp)

配置 Prometheus 服务器地址，然后测试连接：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/UKGCbErWSrXQuWql.webp)F+kzRHG1248BgN91hBPqtNxbML3nLzvb0nw4jU7NTyI=

💡 除了手动配置外，Grafana 还⁠支持通过 Provisio⁠ning 配置文件自动导入数据源和仪表板，这在自动化部署（或者多环境）中很有用。

2）快速导入现成的仪表板模板：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/FazRrk2GQ1psadE8.webp)WBpr9WI72APgOj+DCCZKObs+ofP0VhBHSvqSELGriv0=

3）进入看板页面，查看导入的看板：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/ETZavpE6tUhYdEcZ.webp)

4）查看看板详情，一个仪表板⁠可以包含多个 Pa⁠nel（图表面板）：dWCTYpHEFA/xV8BrvOpKRqkO1d88b9Ip8VkvBeLuZho=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/r514dbNShSxtctAf.webp)

每个 Panel 都可以查看具体的数据、状态和查询语句：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/AZET9sDh6gg1xy5p.webp)nShO7+0zZStNyiJdnnoFDwT4JyyptzNsRjyXLsolAAU=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/TnHwVyqasbB5UYRM.webp)

![](https://pic.code-nav.cn/course_picture/1608440217629360130/fFtmZQcITR05Bb7L.webp)

5）右上角可以将整个仪表板导⁠出为 JSON 格⁠式，便于分享和备份：UzapLzatIvJJsWWs1pRz7879eXluI/+jA6d4qBCHuKE=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/YgolSJ2dKACjBK9t.webp)

![](https://pic.code-nav.cn/course_picture/1608440217629360130/4ISfnZONhwaSkxrA.webp)

同样也可以通过导入 JSON 快速创建仪表板：qo3wYiJtEuojZDmpW2HRDEwGWUH1DzVFQ47Zs4YmYuk=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/pmBTAY6wbAdOtFPT.webp "null")

### 开发实现

环境准备就绪后，接下来在我们⁠的 AI 零代码应⁠用生成平台中实现业务监控功能。nShO7+0zZStNyiJdnnoFDwT4JyyptzNsRjyXLsolAAU=

#### 1、引入依赖

在 `pom.xml` 中添加必要的依赖：

```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>
<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-registry-prometheus</artifactId>
</dependency>
```

建议大家理解每个依赖的作用：

1）[spring-boot-starter-actuator](https://docs.spring.io/spring-boot/reference/actuator/enabling.html)：Actuator 提供生产就绪的监控基础设施，暴露各种管理和监控端点。它是应用与外部监控系统交互的窗口，但本身不负责指标数据的收集。

2）micrometer-core：Micrometer 是真正⁠的指标收集引擎，负责收集 JVM、HTTP⁠、数据库等各种指标数据。它提供统一的 API 让开发者可以创建自定义指标（类似于一个门面），是整个监控体系的数据生产者。nShO7+0zZStNyiJdnnoFDwT4JyyptzNsRjyXLsolAAU=

3）[micrometer-registry-prometheus](https://docs.micrometer.io/micrometer/reference/)：Prometheus Registry 专门负责将 Micrometer 收集的指标数据转换为 Prometheus 格式。它创建 [/actuator/prometheus](https://docs.spring.io/spring-boot/reference/actuator/metrics.html#actuator.metrics.export.prometheus) 端点，让 Prometheus 服务器可以直接拉取标准格式的监控数据。

Prometheus 可以定期访问 `/actuator/prometheus` 端点拉取指标数据，实现对 Spring Boot 应用的持续监控和告警。

总结一下作用：WBpr9WI72APgOj+DCCZKObs+ofP0VhBHSvqSELGriv0=

-   spring-boot-starter-actuator = 端点提供者（开门的）
-   micrometer-core = 数据收集者（干活的）
-   micrometer-registry-prometheus = 格式转换者（翻译的）
-   Prometheus = 数据拉取者（消费的）

![](https://pic.code-nav.cn/course_picture/1608440217629360130/V7dekBQI5ULDLQZ6.webp)

#### 2、编写配置

在 `application.yml` 中添加 Actuator 配置，暴露监控端点：

```yaml
management:
  endpoints:
    web:
      exposure:
        include: health,info,prometheus
  endpoint:
    health:
      show-details: always
```

重启项目后，可以访问端点验证配置。比如健康检查端点：[http://localhost:8123/api/actuator/health](http://localhost:8123/api/actuator/health)WBpr9WI72APgOj+DCCZKObs+ofP0VhBHSvqSELGriv0=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/7Sx5s4YSpod8jL7a.webp)

Prometheus 指标端点：[http://localhost:8123/api/actuator/prometheus](http://localhost:8123/api/actuator/prometheus)，可以看到 Spring Boot 默认提供的各种系统指标。

![](https://pic.code-nav.cn/course_picture/1608440217629360130/tuzF214ObQAHILPW.webp)dWCTYpHEFA/xV8BrvOpKRqkO1d88b9Ip8VkvBeLuZho=

#### 3、监控上下文

由于需要在监听器中获取业务维度信息⁠（比如 appId、u⁠serId），我们可以通过 ThreadLocal 来传递这些参数。

1）在 `monitor` 包下定义上下文类 MonitorContext：UzapLzatIvJJsWWs1pRz7879eXluI/+jA6d4qBCHuKE=

```java
@Data
@Builder
@NoArgsConstructor
@AllArgsConstructor
public class MonitorContext implements Serializable {

    private String userId;

    private String appId;

    @Serial
    private static final long serialVersionUID = 1L;
}
```

还可以按需添加 `requestId`、`chatHistoryId` 等字段。

2）定义上下文持有者 Moni⁠torContext⁠Holder，提供 ThreadLocal 的读、写、清除方法：nShO7+0zZStNyiJdnnoFDwT4JyyptzNsRjyXLsolAAU=

```java
@Slf4j
public class MonitorContextHolder {

    private static final ThreadLocal<MonitorContext> CONTEXT_HOLDER = new ThreadLocal<>();

    /**
     * 设置监控上下文
     */
    public static void setContext(MonitorContext context) {
        CONTEXT_HOLDER.set(context);
    }

    /**
     * 获取当前监控上下文
     */
    public static MonitorContext getContext() {
        return CONTEXT_HOLDER.get();
    }

    /**
     * 清除监控上下文
     */
    public static void clearContext() {
        CONTEXT_HOLDER.remove();
    }
}
```

3）在 `AppServiceImpl` 的 `chatToGenCode` 方法中设置上下文，并在 AI 调用流结束时清理：

```java
// 5. 通过校验后，添加用户消息到对话历史
chatHistoryService.addChatMessage(appId, message, ChatHistoryMessageTypeEnum.USER.getValue(), loginUser.getId());
// 6. 设置监控上下文
MonitorContextHolder.setContext(
        MonitorContext.builder()
                .userId(loginUser.getId().toString())
                .appId(appId.toString())
                .build()
);
// 7. 调用 AI 生成代码（流式）
Flux<String> codeStream = aiCodeGeneratorFacade.generateAndSaveCodeStream(message, codeGenTypeEnum, appId);
// 8. 收集 AI 响应内容并在完成后记录到对话历史
return streamHandlerExecutor.doExecute(codeStream, chatHistoryService, appId, loginUser, codeGenTypeEnum)
        .doFinally(signalType -> {
            // 流结束时清理（无论成功/失败/取消）
            MonitorContextHolder.clearContext();
        });
```

注意清理时机应该是在流结束时⁠，而不是方法返回值⁠之前，这样能确保整个请求周期内都能获取到上下文信息。

#### 4、指标收集器

编写指标收集器，负责收集业务⁠数据并转换为 Pr⁠ometheus 指标。nShO7+0zZStNyiJdnnoFDwT4JyyptzNsRjyXLsolAAU=

这一步不用想太多，尽量把 **最细粒度的数据** 按照维度分类统计就好。

指标收集器需要提供几个方法，⁠分别统计请求信息、⁠错误信息、Token 消耗、响应时间：

```java
@Component
@Slf4j
public class AiModelMetricsCollector {

    @Resource
    private MeterRegistry meterRegistry;

    // 缓存已创建的指标，避免重复创建（按指标类型分离缓存）
    private final ConcurrentMap<String, Counter> requestCountersCache = new ConcurrentHashMap<>();
    private final ConcurrentMap<String, Counter> errorCountersCache = new ConcurrentHashMap<>();
    private final ConcurrentMap<String, Counter> tokenCountersCache = new ConcurrentHashMap<>();
    private final ConcurrentMap<String, Timer> responseTimersCache = new ConcurrentHashMap<>();

    /**
     * 记录请求次数
     */
    public void recordRequest(String userId, String appId, String modelName, String status) {
        String key = String.format("%s_%s_%s_%s", userId, appId, modelName, status);
        Counter counter = requestCountersCache.computeIfAbsent(key, k ->
                Counter.builder("ai_model_requests_total")
                        .description("AI模型总请求次数")
                        .tag("user_id", userId)
                        .tag("app_id", appId)
                        .tag("model_name", modelName)
                        .tag("status", status)
                        .register(meterRegistry)
        );
        counter.increment();
    }

    /**
     * 记录错误
     */
    public void recordError(String userId, String appId, String modelName, String errorMessage) {
        String key = String.format("%s_%s_%s_%s", userId, appId, modelName, errorMessage);
        Counter counter = errorCountersCache.computeIfAbsent(key, k ->
                Counter.builder("ai_model_errors_total")
                        .description("AI模型错误次数")
                        .tag("user_id", userId)
                        .tag("app_id", appId)
                        .tag("model_name", modelName)
                        .tag("error_message", errorMessage)
                        .register(meterRegistry)
        );
        counter.increment();
    }

    /**
     * 记录Token消耗
     */
    public void recordTokenUsage(String userId, String appId, String modelName,
                                 String tokenType, long tokenCount) {
        String key = String.format("%s_%s_%s_%s", userId, appId, modelName, tokenType);
        Counter counter = tokenCountersCache.computeIfAbsent(key, k ->
                Counter.builder("ai_model_tokens_total")
                        .description("AI模型Token消耗总数")
                        .tag("user_id", userId)
                        .tag("app_id", appId)
                        .tag("model_name", modelName)
                        .tag("token_type", tokenType)
                        .register(meterRegistry)
        );
        counter.increment(tokenCount);
    }

    /**
     * 记录响应时间
     */
    public void recordResponseTime(String userId, String appId, String modelName, Duration duration) {
        String key = String.format("%s_%s_%s", userId, appId, modelName);
        Timer timer = responseTimersCache.computeIfAbsent(key, k ->
                Timer.builder("ai_model_response_duration_seconds")
                        .description("AI模型响应时间")
                        .tag("user_id", userId)
                        .tag("app_id", appId)
                        .tag("model_name", modelName)
                        .register(meterRegistry)
        );
        timer.record(duration);
    }
}
```

这里的几个关键点：

1.  选择合适的指标类型：Counter 用于计数（请求次数、错误次数、Token 数量）；Timer 用于时间测量（AI 模型响应时间）
2.  使用缓存避免统计对象重复注册：Micrometer 会为相同的维度组合创建唯一的指标，通过缓存可以重用同一个 Counter / Timer 对象，避免每次调用都执行 `Counter.builder()...register()` 操作。

#### 5、AI 调用监听器

编写 LangChain4j⁠ 监听器来触发指标⁠收集，这是整个监控体系的核心：

```java
@Component
@Slf4j
public class AiModelMonitorListener implements ChatModelListener {

    // 用于存储请求开始时间的键
    private static final String REQUEST_START_TIME_KEY = "request_start_time";
    // 用于监控上下文传递（因为请求和响应事件的触发不是同一个线程）
    private static final String MONITOR_CONTEXT_KEY = "monitor_context";
    
    @Resource
    private AiModelMetricsCollector aiModelMetricsCollector;

    @Override
    public void onRequest(ChatModelRequestContext requestContext) {
        // 记录请求开始时间
        requestContext.attributes().put(REQUEST_START_TIME_KEY, Instant.now());
        // 从监控上下文中获取信息
        MonitorContext context = MonitorContextHolder.getContext();
        String userId = context.getUserId();
        String appId = context.getAppId();
        requestContext.attributes().put(MONITOR_CONTEXT_KEY, context);
        // 获取模型名称
        String modelName = requestContext.chatRequest().modelName();
        // 记录请求指标
        aiModelMetricsCollector.recordRequest(userId, appId, modelName, "started");
    }

    @Override
    public void onResponse(ChatModelResponseContext responseContext) {
        // 从属性中获取监控信息（由 onRequest 方法存储）
        Map<Object, Object> attributes = responseContext.attributes();
        // 从监控上下文中获取信息
        MonitorContext context = (MonitorContext) attributes.get(MONITOR_CONTEXT_KEY);
        String userId = context.getUserId();
        String appId = context.getAppId();
        // 获取模型名称
        String modelName = responseContext.chatResponse().modelName();
        // 记录成功请求
        aiModelMetricsCollector.recordRequest(userId, appId, modelName, "success");
        // 记录响应时间
        recordResponseTime(attributes, userId, appId, modelName);
        // 记录 Token 使用情况
        recordTokenUsage(responseContext, userId, appId, modelName);
    }

    @Override
    public void onError(ChatModelErrorContext errorContext) {
        // 从监控上下文中获取信息
        MonitorContext context = MonitorContextHolder.getContext();
        String userId = context.getUserId();
        String appId = context.getAppId();
        // 获取模型名称和错误类型
        String modelName = errorContext.chatRequest().modelName();
        String errorMessage = errorContext.error().getMessage();
        // 记录失败请求
        aiModelMetricsCollector.recordRequest(userId, appId, modelName, "error");
        aiModelMetricsCollector.recordError(userId, appId, modelName, errorMessage);
        // 记录响应时间（即使是错误响应）
        Map<Object, Object> attributes = errorContext.attributes();
        recordResponseTime(attributes, userId, appId, modelName);
    }


    /**
     * 记录响应时间
     */
    private void recordResponseTime(Map<Object, Object> attributes, String userId, String appId, String modelName) {
        Instant startTime = (Instant) attributes.get(REQUEST_START_TIME_KEY);
        Duration responseTime = Duration.between(startTime, Instant.now());
        aiModelMetricsCollector.recordResponseTime(userId, appId, modelName, responseTime);
    }

    /**
     * 记录Token使用情况
     */
    private void recordTokenUsage(ChatModelResponseContext responseContext, String userId, String appId, String modelName) {
        TokenUsage tokenUsage = responseContext.chatResponse().metadata().tokenUsage();
        if (tokenUsage != null) {
            aiModelMetricsCollector.recordTokenUsage(userId, appId, modelName, "input", tokenUsage.inputTokenCount());
            aiModelMetricsCollector.recordTokenUsage(userId, appId, modelName, "output", tokenUsage.outputTokenCount());
            aiModelMetricsCollector.recordTokenUsage(userId, appId, modelName, "total", tokenUsage.totalTokenCount());
        }
    }
}
```

有几个重要细节需要注意：cZq9/nGwbRXl38gxWuOGAJfnulyo9Sx2vt9GhAJuMwQ=

1.  线程切换问题：请求监听在主线程，但响应监听可能在另一个线程，所以要通过 AI context 的 attributes 传递参数。
2.  时间计算：在请求开始时记录时间戳，在响应完成时计算耗时。
3.  错误处理：即使发生错误也要记录响应时间，便于分析错误请求的特征。

然后需要将监听器注册到 AI 模型配置中。修改 `ReasoningStreamingChatModelConfig` 和 `StreamingChatModelConfig`：

```java
@Resource
private AiModelMonitorListener aiModelMonitorListener;

@Bean
@Scope("prototype")
public StreamingChatModel streamingChatModelPrototype() {
    return OpenAiStreamingChatModel.builder()
            .apiKey(apiKey)
            .baseUrl(baseUrl)
            .modelName(modelName)
            .maxTokens(maxTokens)
            .temperature(temperature)
            .logRequests(logRequests)
            .logResponses(logResponses)
            .listeners(List.of(aiModelMonitorListener))
            .build();
}
```

#### 6、测试验证

通过前端发起一次 AI 对话⁠请求（需要调用 c⁠hatToGenCode 方法），看看会不会触发监听器的方法。

成功触发请求监听，能够获取到上下文信息：cZq9/nGwbRXl38gxWuOGAJfnulyo9Sx2vt9GhAJuMwQ=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/vG7bV96kbnAeeBsv.webp)

触发响应监听，能够获取到请求时间和上下文信息：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/KOdggyolr9cROOhp.webp)F+kzRHG1248BgN91hBPqtNxbML3nLzvb0nw4jU7NTyI=

访问 [http://localhost:8123/api/actuator/prometheus](http://localhost:8123/api/actuator/prometheus) 查看指标数据：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/4o6RQgHolMxwvSSg.webp "null")

可以看到相同维度的指标自动进⁠行了聚合，确认各个⁠指标统计正确。F+kzRHG1248BgN91hBPqtNxbML3nLzvb0nw4jU7NTyI=

💡 其中，我们发现 AI 模型响应时间的最大值有些竟然是 0！这是因为 Micro⁠meter Timer 的 max 指标有一个内置的时间⁠窗口衰减机制，默认情况下时间窗口约 2 分钟，在时间窗口内没有新数据时，max 值会重置为 0。这样设计是为了反映最近时间段的性能，而不是历史累积最大值。

![](https://pic.code-nav.cn/course_picture/1608440217629360130/uO63CxMsvgK0M6zM.webp)

#### 7、Prometheus 配置

现在需要配置 Prometh⁠eus 定期从我们⁠的应用拉取监控数据。在项目内创建配置文件，便于版本管理：

```yaml
# Prometheus 配置文件
global:
  scrape_interval: 15s      # 全局抓取间隔
  evaluation_interval: 15s  # 规则评估间隔

# 告警管理器配置 (可选)
alerting:
 alertmanagers:
   - static_configs:
       - targets:
         # - alertmanager:9093

# 规则文件配置
rule_files:
  # - "alert_rules.yml"  # 可以添加告警规则

# 抓取配置
scrape_configs:
  # Prometheus 自身监控
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  # Spring Boot 应用监控
  - job_name: 'yu-ai-code-mother'
    metrics_path: '/api/actuator/prometheus'  # Spring Boot Actuator 端点
    static_configs:
      - targets: ['localhost:8123']  # 应用服务器地址
    scrape_interval: 10s  # 每 10 秒抓取一次
    scrape_timeout: 10s   # 抓取超时时间
```

然后使用新配置启动 Prometheus：UzapLzatIvJJsWWs1pRz7879eXluI/+jA6d4qBCHuKE=

```bash
./prometheus --config.file=<配置文件路径>
```

在 Prometheus 的 `Status -> Target health` 页面可以查看抓取状态：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/19FSThzglMI9YSlo.webp)F+kzRHG1248BgN91hBPqtNxbML3nLzvb0nw4jU7NTyI=

测试查询我们自定义的指标：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/j19lZWSxSEhAbU3A.webp)

#### 8、Grafana 可视化监控配置

有了数据后，接下来在 Grafana 中创建可视化看板。

1）手动创建仪表板：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/QLNNcq8H3VcrvRzS.webp)WBpr9WI72APgOj+DCCZKObs+ofP0VhBHSvqSELGriv0=

2）配置图表，以应用 Token 消耗排行为例：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/8evvgAVVMKLjfQ0z.webp)

配置步骤：F+kzRHG1248BgN91hBPqtNxbML3nLzvb0nw4jU7NTyI=

1.  选择图表类型为 Bar Chart，设置基础信息
2.  在查询编辑器中填写 PromQL 表达式：`topk(10, sum(ai_model_tokens_total{token_type="total"}) by (app_id))`
3.  查询编辑器中，勾选 `Instant` 选项。这样只会返回当前时刻的值，而不是时间序列
4.  查询编辑器中，修改面板类型，将面板类型从 Time series 改为 Table

3）保存看板：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/Vk0ONZ5iHBul7uPY.webp)F+kzRHG1248BgN91hBPqtNxbML3nLzvb0nw4jU7NTyI=

效果如图：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/XASbkmR2dBvqXfJU.webp)

但是手动创建图表比较麻烦，更高效的方式是让 A⁠I 帮我们生成完整的看板 JS⁠ON 配置。需要给 AI 提供需求说明、数据样例和 Grafana 规范，提示词如下：F+kzRHG1248BgN91hBPqtNxbML3nLzvb0nw4jU7NTyI=

```markdown
帮我根据分析需求、数据上报相关代码、示例从 Prometheus 收集到的数据，来生成 Grafana 看板的 JSON 导入代码，全部汇总到一个看板中。

相关的规范参考：https://grafana.com/docs/grafana/latest/dashboards/build-dashboards/view-dashboard-json-model/

## 需求

// ... 补充分析需求

## 数据上报相关代码

// ... 补充 AiModelMetricsCollector.java 的代码

## 示例收集到的数据

HELP ai_model_requests_total AI模型总请求次数
TYPE ai_model_requests_total counter
ai_model_requests_total{app_id="313129227198590976",model_name="deepseek-chat",status="started",user_id="302588523967918080"} 2.0
ai_model_requests_total{app_id="313129227198590976",model_name="deepseek-chat",status="success",user_id="302588523967918080"} 2.0

HELP ai_model_response_duration_seconds AI模型响应时间
TYPE ai_model_response_duration_seconds summary
ai_model_response_duration_seconds_count{app_id="313129227198590976",model_name="deepseek-chat",user_id="302588523967918080"} 2
ai_model_response_duration_seconds_sum{app_id="313129227198590976",model_name="deepseek-chat",user_id="302588523967918080"} 91.285863

HELP ai_model_tokens_total AI模型Token消耗总数
TYPE ai_model_tokens_total counter
ai_model_tokens_total{app_id="313129227198590976",model_name="deepseek-chat",token_type="input",user_id="302588523967918080"} 1321.0
ai_model_tokens_total{app_id="313129227198590976",model_name="deepseek-chat",token_type="output",user_id="302588523967918080"} 519.0
ai_model_tokens_total{app_id="313129227198590976",model_name="deepseek-chat",token_type="total",user_id="302588523967918080"} 1840.0
```

💡 注意，AI 可能无法一⁠次性输出满意的看板⁠，可以让 AI 单独修复某个图表或者人工调整。

可以通过导入生成的 JSON 配置快速创建完整的看板：1vM0bC71h2RCfUkazMGszlP9tIpAZTvdkFrdc8O6/+w=

![](https://pic.code-nav.cn/course_picture/1608440217629360130/KQrX8OcRv57PL3BV.webp)

![](https://pic.code-nav.cn/course_picture/1608440217629360130/gr6xKCkLCsuWOwX0.webp)

看板代码可以在源码仓库获取：[https://github.com/liyupi/yu-ai-code-mother/blob/master/grafana/ai\_model\_grafana\_config.json](https://github.com/liyupi/yu-ai-code-mother/blob/master/grafana/ai_model_grafana_config.json)（记得点个 star 再走哦，感谢支持！）nShO7+0zZStNyiJdnnoFDwT4JyyptzNsRjyXLsolAAU=

效果如图：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/hw891UGc22lEidGL.webp)

## 四、扩展思路

通过本节的开发，我们已经构建⁠了完整的可观测性体⁠系，可以按需扩展。

### 1、告警能力

可以通过 Prometheus 的 [Alertmanager](https://prometheus.io/docs/alerting/latest/alertmanager/) 实现告警功能。主要是配置告警规则，比如当指标超过阈值时自动发送通知。EVevk6+j/BC/ssKO5aUZF8Rusnkp1o/HghJkPkRChGQ=

举个例子：

```yaml
groups:
  - name: ai_model_alerts
    rules:
      - alert: HighErrorRate
        expr: sum(rate(ai_model_requests_total{status="error"}[5m])) / sum(rate(ai_model_requests_total[5m])) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "AI模型错误率过高"
          description: "错误率已超过10%，持续5分钟"
      - alert: SlowResponse
        expr: avg(ai_model_response_duration_seconds) > 30
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "AI模型响应时间过长"
          description: "平均响应时间超过30秒"
```

### 2、更多分析

基于 Token 消耗数据，可以实现详细的成本分析功能：

1.  用户级成本统计：按用户统计 Token 使用量，支持计费功能
2.  应用级成本分析：识别成本最高的应用，优化资源分配
3.  模型成本对比：分析不同模型的性价比，指导模型选择

给大家整理了需求对应的计算表达式表格，仅供参考：EVevk6+j/BC/ssKO5aUZF8Rusnkp1o/HghJkPkRChGQ=

dWCTYpHEFA/xV8BrvOpKRqkO1d88b9Ip8VkvBeLuZho=EVevk6+j/BC/ssKO5aUZF8Rusnkp1o/HghJkPkRChGQ=UzapLzatIvJJsWWs1pRz7879eXluI/+jA6d4qBCHuKE=dWCTYpHEFA/xV8BrvOpKRqkO1d88b9Ip8VkvBeLuZho=nShO7+0zZStNyiJdnnoFDwT4JyyptzNsRjyXLsolAAU=UzapLzatIvJJsWWs1pRz7879eXluI/+jA6d4qBCHuKE=dWCTYpHEFA/xV8BrvOpKRqkO1d88b9Ip8VkvBeLuZho=dWCTYpHEFA/xV8BrvOpKRqkO1d88b9Ip8VkvBeLuZho=dWCTYpHEFA/xV8BrvOpKRqkO1d88b9Ip8VkvBeLuZho=dWCTYpHEFA/xV8BrvOpKRqkO1d88b9Ip8VkvBeLuZho=F+kzRHG1248BgN91hBPqtNxbML3nLzvb0nw4jU7NTyI=UzapLzatIvJJsWWs1pRz7879eXluI/+jA6d4qBCHuKE=F+kzRHG1248BgN91hBPqtNxbML3nLzvb0nw4jU7NTyI=dWCTYpHEFA/xV8BrvOpKRqkO1d88b9Ip8VkvBeLuZho=

|分析名称|拥有的指标和维度|计算表达式dWCTYpHEFA/xV8BrvOpKRqkO1d88b9Ip8VkvBeLuZho=|
|---|---|---|
|模型调用分析统计不同时间窗口内各模型、用户、应用的调用次数趋势，支持分钟/小时/天级别的时间聚合|ai\_model\_requests\_total{status="success"}维度：user\_id, app\_id, model\_name, status|按模型（5分钟窗口）：sum(rate(ai\_model\_requests\_total{status="success"}\[5m\])) by (model\_name)按用户（1小时窗口）：sum(increase(ai\_model\_requests\_total{status="success"}\[1h\])) by (user\_id)按应用（1天窗口）：sum(increase(ai\_model\_requests\_total{status="success"}\[1d\])) by (app\_id)总体调用趋势：sum(rate(ai\_model\_requests\_total{status="success"}\[5m\]))UzapLzatIvJJsWWs1pRz7879eXluI/+jA6d4qBCHuKE=|
|模型性能分析分析各模型的响应时间性能，包括平均响应时间和不同百分位数（P50/P90/P95/P99），用于识别性能瓶颈和异常值|ai\_model\_response\_duration\_seconds维度：user\_id, app\_id, model\_name|平均响应时间：avg(ai\_model\_response\_duration\_seconds) by (model\_name)P99百分位数：histogram\_quantile(0.99, sum(rate(ai\_model\_response\_duration\_seconds\_bucket\[5m\])) by (le, model\_name))UzapLzatIvJJsWWs1pRz7879eXluI/+jA6d4qBCHuKE=|
|Token 消耗分析监控不同时间窗口内Token消耗情况，区分输入、输出、总Token，支持按模型、用户、应用维度聚合|ai\_model\_tokens\_total维度：user\_id, app\_id, model\_name, token\_type|输入Token速率（每秒）：sum(rate(ai\_model\_tokens\_total{token\_type="input"}\[5m\])) by (model\_name)总Token速率（每秒）：sum(rate(ai\_model\_tokens\_total{token\_type="total"}\[5m\])) by (model\_name)1天Token消耗量：sum(increase(ai\_model\_tokens\_total{token\_type="total"}\[1d\])) by (model\_name)dWCTYpHEFA/xV8BrvOpKRqkO1d88b9Ip8VkvBeLuZho=|
|热门应用排行按调用次数对应用进行排序，识别调用AI最频繁的应用，支持不同时间窗口（1小时/24小时/7天）|ai\_model\_requests\_total{status="success"}维度：app\_id, model\_name|7天Top10应用：topk(10, sum(increase(ai\_model\_requests\_total{status="success"}\[7d\])) by (app\_id))应用调用频率排名：sort\_desc(sum(rate(ai\_model\_requests\_total{status="success"}\[5m\])) by (app\_id))p+CfRPZxNEuU7hG8dzfPcN4R10eC9eypGHmTaRf/x7c=|
|用户活跃排行按调用次数对用户进行排序，识别调用AI最频繁的用户，支持不同时间窗口分析|ai\_model\_requests\_total{status="success"}维度：user\_id, model\_name|24小时Top10用户：topk(10, sum(increase(ai\_model\_requests\_total{status="success"}\[24h\])) by (user\_id))用户调用频率排名：sort\_desc(sum(rate(ai\_model\_requests\_total{status="success"}\[5m\])) by (user\_id))用户活跃度趋势：sum(rate(ai\_model\_requests\_total{status="success"}\[5m\])) by (user\_id)UzapLzatIvJJsWWs1pRz7879eXluI/+jA6d4qBCHuKE=|
|应用Token消耗排行按Token消耗量对应用进行排序，识别消耗最高的应用，帮助成本控制和资源优化|ai\_model\_tokens\_total{token\_type="total"}维度：app\_id, model\_name|应用Token消耗速率排名：sort\_desc(sum(rate(ai\_model\_tokens\_total{token\_type="total"}\[5m\])) by (app\_id))EVevk6+j/BC/ssKO5aUZF8Rusnkp1o/HghJkPkRChGQ=|
|用户Token消耗排行按Token消耗量对用户进行排序，识别消耗最高的用户，支持成本分析和用户行为分析|ai\_model\_tokens\_total{token\_type="total"}维度：user\_id, model\_name|24小时Top10用户（总Token）：topk(10, sum(increase(ai\_model\_tokens\_total{token\_type="total"}\[24h\])) by (user\_id))用户Token消耗速率排名：sort\_desc(sum(rate(ai\_model\_tokens\_total{token\_type="total"}\[5m\])) by (user\_id))F+kzRHG1248BgN91hBPqtNxbML3nLzvb0nw4jU7NTyI=|
|错误分析统计各模型的失败次数，分析不同错误类型的分布占比，识别系统稳定性问题和常见错误模式|ai\_model\_errors\_total, ai\_model\_requests\_total{status="error"}维度：model\_name, error\_message, user\_id, app\_id|模型错误次数（24小时）：sum(increase(ai\_model\_requests\_total{status="error"}\[24h\])) by (model\_name)错误类型分布：sum(increase(ai\_model\_errors\_total\[24h\])) by (error\_message)总体错误率：sum(rate(ai\_model\_requests\_total{status="error"}\[5m\])) / sum(rate(ai\_model\_requests\_total\[5m\])) \* 100qo3wYiJtEuojZDmpW2HRDEwGWUH1DzVFQ47Zs4YmYuk=|

通过监控数据，还可以帮忙发现一些性能问题，比如：

1.  慢调用识别：找出响应时间最长的一批请求，分析请求特点
2.  热点分析：识别访问量最大的模型或提示词，按需进行缓存
3.  资源使用分析：根据 Token 消耗模式，优化模型部署策略

### 3、时序数据库

在监控系统中，我们会产生大量的时间序列数据。如果数据量特别大，或者对时间序列查询有特殊需求，可以考虑使用专门的时序数据库，比如 [InfluxDB](https://www.influxdata.com/)、[TDengine](https://tdengine.com/) 等。

鱼皮之前用过 InfluxD⁠B，它就是专门为时⁠序数据设计的数据库，具有以下特点：EVevk6+j/BC/ssKO5aUZF8Rusnkp1o/HghJkPkRChGQ=

1.  高性能写入：专门优化了时序数据的写入性能，能够处理大量的并发写入
2.  高效压缩：针对时序数据的特点进行了压缩优化，存储效率很高
3.  灵活查询：提供了 InfluxQL 查询语言，支持时间窗口、聚合、分组等操作，而且 Grafana 也能够轻松 [对接 InfluxDB 的数据](https://grafana.com/docs/grafana/latest/getting-started/get-started-grafana-influxdb/)。
4.  数据保留策略：可以设置数据的自动过期和压缩策略，便于数据生命周期管理

时序数据库中的数据存储结构类似这样：

![](https://pic.code-nav.cn/course_picture/1608440217629360130/CdStQeY5wIcm6KP3.webp)qo3wYiJtEuojZDmpW2HRDEwGWUH1DzVFQ47Zs4YmYuk=

在我们的场景中，Prometheus 已经⁠能很好地满足需求，但如果未来⁠数据量增长到 TB 级别，或者需要更复杂的时序分析，可以考虑迁移到 InfluxDB。

## 总结

通过本节的学习，我们成功为 AI 零代码应用生成平台⁠构建了完整的可观测性体系。从基础的⁠系统监控到深入的业务分析，从实时指标收集到直观的可视化展示，这套监控系统能够全方位保障平台的稳定运行。cZq9/nGwbRXl38gxWuOGAJfnulyo9Sx2vt9GhAJuMwQ=

希望大家掌握这些技术、以及实⁠现可观测性的套路，⁠能够为项目搭建合理的监控分析系统，构建更可靠的 AI 应用。

qo3wYiJtEuojZDmpW2HRDEwGWUH1DzVFQ47Zs4YmYuk=
